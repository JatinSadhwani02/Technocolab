{"cells":[{"metadata":{},"cell_type":"markdown","source":"**This notebook is an exercise in the [Feature Engineering](https://www.kaggle.com/learn/feature-engineering) course.  You can reference the tutorial at [this link](https://www.kaggle.com/matleonard/categorical-encodings).**\n\n---\n"},{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nIn this exercise you'll apply more advanced encodings to encode the categorical variables ito improve your classifier model. The encodings you will implement are:\n\n- Count Encoding\n- Target Encoding\n- CatBoost Encoding\n\nYou'll refit the classifier after each encoding to check its performance on hold-out data. \n\nBegin by running the next code cell to set up the notebook."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set up code checking\n# This can take a few seconds\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.feature_engineering.ex2 import *","execution_count":1,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  elif pd.api.types.is_categorical(cols):\n/opt/conda/lib/python3.7/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  elif pd.api.types.is_categorical(cols):\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"The next code cell repeats the work that you did in the previous exercise."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing, metrics\nimport lightgbm as lgb\n\nclicks = pd.read_parquet('../input/feature-engineering-data/baseline_data.pqt')","execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Next, we define a couple functions that you'll use to test the encodings that you implement in this exercise."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data_splits(dataframe, valid_fraction=0.1):\n    \"\"\"Splits a dataframe into train, validation, and test sets.\n\n    First, orders by the column 'click_time'. Set the size of the \n    validation and test sets with the valid_fraction keyword argument.\n    \"\"\"\n\n    dataframe = dataframe.sort_values('click_time')\n    valid_rows = int(len(dataframe) * valid_fraction)\n    train = dataframe[:-valid_rows * 2]\n    # valid size == test size, last two sections of the data\n    valid = dataframe[-valid_rows * 2:-valid_rows]\n    test = dataframe[-valid_rows:]\n    \n    return train, valid, test\n\ndef train_model(train, valid, test=None, feature_cols=None):\n    if feature_cols is None:\n        feature_cols = train.columns.drop(['click_time', 'attributed_time',\n                                           'is_attributed'])\n    dtrain = lgb.Dataset(train[feature_cols], label=train['is_attributed'])\n    dvalid = lgb.Dataset(valid[feature_cols], label=valid['is_attributed'])\n    \n    param = {'num_leaves': 64, 'objective': 'binary', \n             'metric': 'auc', 'seed': 7}\n    num_round = 1000\n    bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], \n                    early_stopping_rounds=20, verbose_eval=False)\n    \n    valid_pred = bst.predict(valid[feature_cols])\n    valid_score = metrics.roc_auc_score(valid['is_attributed'], valid_pred)\n    print(f\"Validation AUC score: {valid_score}\")\n    \n    if test is not None: \n        test_pred = bst.predict(test[feature_cols])\n        test_score = metrics.roc_auc_score(test['is_attributed'], test_pred)\n        return bst, valid_score, test_score\n    else:\n        return bst, valid_score","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run this cell to get a baseline score. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Baseline model\")\ntrain, valid, test = get_data_splits(clicks)\n_ = train_model(train, valid)","execution_count":4,"outputs":[{"output_type":"stream","text":"Baseline model\nValidation AUC score: 0.9622743228943659\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### 1) Categorical encodings and leakage\n\nThese encodings are all based on statistics calculated from the dataset like counts and means. \n\nConsidering this, what data should you be using to calculate the encodings?  Specifically, can you use the validation data?  Can you use the test data?\n\nRun the following line after you've decided your answer."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_1.solution()","execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"questionId\": \"1_LeakageQuestion\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: You should calculate the encodings from the training set only. If you include data from the validation and test sets into the encodings, you'll overestimate the model's performance. You should in general be vigilant to avoid leakage, that is, including any information from the validation and test sets into the model. For a review on this topic, see our lesson on [data leakage](https://www.kaggle.com/alexisbcook/data-leakage)","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> You should calculate the encodings from the training set only. If you include data from the validation and test sets into the encodings, you'll overestimate the model's performance. You should in general be vigilant to avoid leakage, that is, including any information from the validation and test sets into the model. For a review on this topic, see our lesson on [data leakage](https://www.kaggle.com/alexisbcook/data-leakage)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 2) Count encodings\n\nBegin by running the next code cell to get started."},{"metadata":{"trusted":true},"cell_type":"code","source":"import category_encoders as ce\n\ncat_features = ['ip', 'app', 'device', 'os', 'channel']\ntrain, valid, test = get_data_splits(clicks)","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, encode the categorical features `['ip', 'app', 'device', 'os', 'channel']` using the count of each value in the data set. \n- Using `CountEncoder` from the `category_encoders` library, fit the encoding using the categorical feature columns defined in `cat_features`. \n- Then apply the encodings to the train and validation sets, adding them as new columns with names suffixed `\"_count\"`."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the count encoder\ncount_enc = ce.CountEncoder(cols=cat_features)\n\n\n# Learn encoding from the training set\ncount_enc.fit(train[cat_features])\n\n# Apply encoding to the train and validation sets as new columns\n# Make sure to add `_count` as a suffix to the new columns\ntrain_encoded = train.join(count_enc.transform(train[cat_features]).add_suffix('_count'))\nvalid_encoded = valid.join(count_enc.transform(valid[cat_features]).add_suffix('_count'))\n\n# Check your answer\nq_2.check()","execution_count":9,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  elif pd.api.types.is_categorical(cols):\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.125, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"2_CountEncodings\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Uncomment if you need some guidance\n# q_2.hint()\n#q_2.solution()","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run the next code cell to see how count encoding changes the results."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the model on the encoded datasets\n# This can take around 30 seconds to complete\n_ = train_model(train_encoded, valid_encoded)","execution_count":11,"outputs":[{"output_type":"stream","text":"Validation AUC score: 0.9653051135205329\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Count encoding improved our model's score!"},{"metadata":{},"cell_type":"markdown","source":"### 3) Why is count encoding effective?\nAt first glance, it could be surprising that count encoding helps make accurate models. \nWhy do you think is count encoding is a good idea, or how does it improve the model score?\n\nRun the following line after you've decided your answer."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_3.solution()","execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"questionId\": \"3_CountEncodingEffectiveness\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n    Rare values tend to have similar counts (with values like 1 or 2), so you can classify rare \n    values together at prediction time. Common values with large counts are unlikely to have \n    the same exact count as other values. So, the common/important values get their own \n    grouping.\n    ","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n    Rare values tend to have similar counts (with values like 1 or 2), so you can classify rare \n    values together at prediction time. Common values with large counts are unlikely to have \n    the same exact count as other values. So, the common/important values get their own \n    grouping.\n    "},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 4) Target encoding\n\nHere you'll try some supervised encodings that use the labels (the targets) to transform categorical features. The first one is target encoding. \n- Create the target encoder from the `category_encoders` library. \n- Then, learn the encodings from the training dataset, apply the encodings to all the datasets, and retrain the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the target encoder. You can find this easily by using tab completion.\n# Start typing ce. the press Tab to bring up a list of classes and functions.\ntarget_enc = ce.TargetEncoder(cols=cat_features)\n\n# Learn encoding from the training set. Use the 'is_attributed' column as the target.\ntarget_enc.fit(train[cat_features], train['is_attributed'])\n\n# Apply encoding to the train and validation sets as new columns\n# Make sure to add `_target` as a suffix to the new columns\ntrain_encoded = train.join(target_enc.transform(train[cat_features]).add_suffix('_target'))\nvalid_encoded = valid.join(target_enc.transform(valid[cat_features]).add_suffix('_target'))\n\n\n\n# Check your answer\nq_4.check()","execution_count":14,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  elif pd.api.types.is_categorical(cols):\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.125, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"4_TargetEncodings\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Uncomment these if you need some guidance\n#q_4.hint()\n#q_4.solution()","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run the next cell to see how target encoding affects your results."},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = train_model(train_encoded, valid_encoded)","execution_count":16,"outputs":[{"output_type":"stream","text":"Validation AUC score: 0.9540530347873288\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### 5) Try removing IP encoding\n\nIf you leave `ip` out of the encoded features and retrain the model with target encoding, you should find that the score increases and is above the baseline score! Why do you think the score is below baseline when we encode the IP address but above baseline when we don't?\n\nRun the following line after you've decided your answer."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_5.solution()","execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"questionId\": \"5_RemoveIPEncoding\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n    Target encoding attempts to measure the population mean of the target for each \n    level in a categorical feature. This means when there is less data per level, the \n    estimated mean will be further away from the \"true\" mean, there will be more variance. \n    There is little data per IP address so it's likely that the estimates are much noisier\n    than for the other features. The model will rely heavily on this feature since it is \n    extremely predictive. This causes it to make fewer splits on other features, and those\n    features are fit on just the errors left over accounting for IP address. So, the \n    model will perform very poorly when seeing new IP addresses that weren't in the \n    training data (which is likely most new data). Going forward, we'll leave out the IP feature when trying\n    different encodings.\n    ","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n    Target encoding attempts to measure the population mean of the target for each \n    level in a categorical feature. This means when there is less data per level, the \n    estimated mean will be further away from the \"true\" mean, there will be more variance. \n    There is little data per IP address so it's likely that the estimates are much noisier\n    than for the other features. The model will rely heavily on this feature since it is \n    extremely predictive. This causes it to make fewer splits on other features, and those\n    features are fit on just the errors left over accounting for IP address. So, the \n    model will perform very poorly when seeing new IP addresses that weren't in the \n    training data (which is likely most new data). Going forward, we'll leave out the IP feature when trying\n    different encodings.\n    "},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 6) CatBoost Encoding\n\nThe CatBoost encoder is supposed to work well with the LightGBM model. Encode the categorical features with `CatBoostEncoder` and train the model on the encoded data again."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove IP from the encoded features\ncat_features = ['app', 'device', 'os', 'channel']\n\ntrain, valid, test = get_data_splits(clicks)\n# Create the CatBoost encoder\ncb_enc = ce.CatBoostEncoder(cols=cat_features, random_state=7)\n\n# Learn encoding from the training set\ncb_enc.fit(train[cat_features], train['is_attributed'])\n\n\n# Apply encoding to the train and validation sets as new columns\n# Make sure to add `_cb` as a suffix to the new columns\ntrain_encoded = train.join(cb_enc.transform(train[cat_features]).add_suffix('_cb'))\nvalid_encoded = valid.join(cb_enc.transform(valid[cat_features]).add_suffix('_cb'))\n\n# Check your answer\nq_6.check()","execution_count":19,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n  elif pd.api.types.is_categorical(cols):\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.125, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"6_CatBoostEncodings\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Uncomment these if you need some guidance\n#q_6.hint()\n#q_6.solution()","execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 1, \"questionId\": \"6_CatBoostEncodings\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\n\n    # remove IP from the encoded features\n    cat_features = ['app', 'device', 'os', 'channel']\n\n    train, valid, test = get_data_splits(clicks)\n    \n    # Have to tell it which features are categorical when they aren't strings\n    cb_enc = ce.CatBoostEncoder(cols=cat_features, random_state=7)\n\n    # Learn encoding from the training set\n    cb_enc.fit(train[cat_features], train['is_attributed'])\n\n    # Apply encoding to the train and validation sets\n    train_encoded = train.join(cb_enc.transform(train[cat_features]).add_suffix('_cb'))\n    valid_encoded = valid.join(cb_enc.transform(valid[cat_features]).add_suffix('_cb'))\n    \n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\n\n    # remove IP from the encoded features\n    cat_features = ['app', 'device', 'os', 'channel']\n\n    train, valid, test = get_data_splits(clicks)\n    \n    # Have to tell it which features are categorical when they aren't strings\n    cb_enc = ce.CatBoostEncoder(cols=cat_features, random_state=7)\n\n    # Learn encoding from the training set\n    cb_enc.fit(train[cat_features], train['is_attributed'])\n\n    # Apply encoding to the train and validation sets\n    train_encoded = train.join(cb_enc.transform(train[cat_features]).add_suffix('_cb'))\n    valid_encoded = valid.join(cb_enc.transform(valid[cat_features]).add_suffix('_cb'))\n    \n```"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Run the next code cell to see how the CatBoost encoder changes your results."},{"metadata":{"trusted":false},"cell_type":"code","source":"_ = train_model(train_encoded, valid_encoded)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Keep Going\n\nNow you are ready to **[generate completely new features](https://www.kaggle.com/matleonard/feature-generation)** from the data."},{"metadata":{},"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/161443) to chat with other Learners.*"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}